M=3
x=2
dhyper(x,M,N-M,n2)
p5= choose(0,3)*choose(7,4) / choose(10,4)
p5
p0= choose(3,0)*choose(7,4) / choose(10,4)
p0
p1=choose(3,1)*choose(7,3) / choose(10,4)
p1
p2=choose(3,2)*choose(7,2) / choose(10,4)
p2
p0+p1+p2
dhyper(0:x,M,N-M,n2)
sum(dhyper(0:x,M,N-M,n2))
phyper(x,M,N-M,n2)
lamda = 3
x=5
p5 = (exp(-lamda)*lamda^x)/factorial(x)
p5
lamda = 3
x=5
p5 = (exp(-lamda)*lamda^x)/factorial(x)
p5
#literal b
p0 = (exp(-lamda)*lamda^0)/factorial(0)
p0
p1 = (exp(-lamda)*lamda^1)/factorial(1)
p1
p2 = (exp(-lamda)*lamda^2)/factorial(2)
p2
p0+p1+p2
sum(dpois(0:2,lamda))
ppois(2, lamda)
knitr::opts_chunk$set(echo = TRUE)
dias <- c("Lunes", "Martes", "Miércoles", "Jueves", "Viernes")
horas <- c(5.6, 3.7, 6.2, 5.6, 7.2)
tabla <- as.data.frame(cbind(dias, horas))
knitr::kable(t(tabla))
A=7
B=10
fx = function(x){
(x/x)/(B-A)
}
prob = integrate(fx, 7, 8.8)$value
prob
A=7
B=10
fx = function(x){
(x/x)/(B-A)
}
prob = integrate(fx, 7, 8.8)$value
prob
f8=punif(8.8,7,10)
f7 = punif(7,7,10)
prob = f8 - f7
prob
prop = integrate(fx, 7.4, 9.5)$value
prop
prop = integrate(fx, 8.5, 10)$value
prob
f10 = punif(8.5,7,10)
1-f10
lambda = 1/4
fx = function(x){
lambda*exp(-lambda*x)
}
curve (fx, 0, 10)
abline(v=3, col=2)
abline(v=3, col=2)
p3 = integrate(fx,0,3)$value
p3
pexp(3)
pexp(3, 1/4)
pexp(3, lambda)
p = p3
n=6
1-pbinom(3,6,p3)
pexp(5, lambda)
#EJERCICIO 1.14
# Datos de la muestra
muestra <- c(572, 572, 573, 568, 569, 575, 565, 570)
# a) Calcular la media y la mediana de la muestra
media <- mean(muestra)
mediana <- median(muestra)
# Mostrar la media y la mediana
cat("Media de la muestra:", media, "\n")
cat("Mediana de la muestra:", mediana, "\n")
# b) Obtener la varianza, la desviación estándar y el rango de la muestra
varianza <- var(muestra)
desviacion_estandar <- sd(muestra)
rango <- range(muestra)
amplitud_rango <- diff(rango)
# Mostrar la varianza, la desviación estándar y el rango
cat("Varianza de la muestra:", varianza, "\n")
cat("Desviación estándar de la muestra:", desviacion_estandar, "\n")
cat("Rango de la muestra:", rango, "\n")
cat("Amplitud del rango:", amplitud_rango, "\n")
# c) Comentarios acerca de la calidad de los neumáticos
cat("\nComentarios acerca de la calidad de los neumáticos:\n")
cat("La media es de", media, "mm, que está muy cerca del valor ideal de 570 mm.\n")
cat("La mediana es de", mediana, "mm, que también está cerca del valor ideal.\n")
cat("La varianza es de", varianza, "mm^2, y la desviación estándar es de", desviacion_estandar, "mm,\n")
cat("lo que indica que hay una cierta variabilidad en los diámetros de los neumáticos,\n")
cat("pero no parece ser excesiva. El rango de los datos es de", amplitud_rango, "mm,\n")
cat("lo que muestra que hay una diferencia de", amplitud_rango, "mm entre el neumático más grande y el más pequeño.\n")
cat("En general, la calidad de los neumáticos parece ser bastante buena,\n")
cat("ya que los diámetros están bastante cerca del valor ideal de 570 mm.")
MEDIANA
mediana
x = function(x){
(1/sqrt(2*pi*sigma^2))*exp(-(x - mu)^2/sigma^2)
}
curve(fx,4,-4)
mu = 0
sigma = 1
x = function(x){
(1/sqrt(2*pi*sigma^2))*exp(-(x - mu)^2/sigma^2)
}
curve(fx,4,-4)f
curve(fx,4,-4)
fx = function(x){
(1/sqrt(2*pi*sigma^2))*exp(-(x - mu)^2/sigma^2)
}
curve(fx,4,-4)
abline(v=1.43, col = 2)
integrate(fx, -Inf, 1.43)$value
pnorm(1.43, mu, sigma)
fx = function(x){
(1/sqrt(2*pi*sigma^2))*exp(-(x-mu)^2/2*sigma^2)
}
curve(fx,4,-4)
abline(v=1.43, col = 2)
integrate(fx, -Inf, 1.43)$value
pnorm(1.43, mu, sigma)
### 2.6. Probabilidades condicionales
### 2.7. Regla de multiplicacion
### 2.8. Tablas de probabilidad
### 2.9. Teorema de la probabilidad total
### 2.10. Teorema de Bayes
###################################
# DISTRIBUCIONES RELACIONADAS A LA NORMAL
# OJO: uso de prefijos de funciones: d., p., q., r.
###################################
# ESTUDIO DE LOS ESTIMADORES PARA UNA MEDIA
set.seed(1234) #fijamos semillas
# generamos 1000 muestras uniformes (0,1) de tamaño n = 50
datos <- replicate(1000, runif(50))
#histograma de las muestras
hist(datos)
mean(datos)# OJO: la media teórica es el valor de 0.5
sd(datos)
sqrt(1/12) # OJO: varianza teórica (a-b)^2/12
# Consideraremos dos estimadores para la media poblacional teorica
# estimador 1: el promedio
# estimador 2: la mediana
# calculamos ambos estimadores en las 1000 muestras
est1 <- apply(datos, 2, mean)
est2 <- apply(datos, 2, median)
#OJO: se observa que  los estimadores son v.a.
# comparamos los histogramas de los estimadores
windows()
par(mfrow = c(1,2))
hist(est1)
hist(est2)
par(mfrow = c(1,1))
# OJO: ninguno de los estimadores sigue una distribución uniforme (0,1)
# comparamos los estadisticos
mean(est1)
mean(est2)
# los dos estimadores aproximan al parametro = 0.5
# calculamos el sesgo de cada estimador
sesgo1 <- mean(est1) - 0.5
sesgo1
sesgo2 <- mean(est2) - 0.5
sesgo2
# ambos estimadores tiene sesgo casi nulos (est 1 < est 2)
#calculamos la varianza de cada estimador
var1 <- var(est1)
var1
var2 <- var(est2)
var2
# estimador 1 tiene menos variabilidad que el estimador 2
#calculamos el error cuadratico medio
ecm1 <- sesgo1^2 + var1
ecm1
ecm2 <- sesgo2^2 + var2
ecm2
# el estimador 1 (promedio) es mas eficiente que el estimador 2 (mediana)
###################################
# TEOREMA CENTRAL DEL LIMITE
# se tomaron muestras de tamaño n = 50, y se obtuvo el promedio
# en cada muestra. Para este estimador sucede lo siguiente:
mean(est1) # su media "coincide" con la media teorica = 0.5
sd(est1) # desviacion tipica del estimador
sqrt(1/12)/sqrt(50) # error tipico = desv. del estimador
# Visualizacion del teorema central del limite
hist(est1, freq = FALSE, ylim =c(0,10))
curve(dnorm(x, 0.5, sqrt(1/12)/sqrt(50) ), 0.3, 0.7, add = TRUE, col = 2)
###################################
# ESTIMACION DE LA VARIANZA POBLACIONAL
#Ojo: la varianza poblacional teorica es = 1/12
1/12
# calculamos dos estimadores: varianza muestral y cuasivarianza
var.1 <- apply(datos, 2, var) #cuasivarianza
varp.f <- function(x) mean((x-mean(x))^2) #funcion varianza muestral
var.2 <- apply(datos, 2, varp.f) #varianza muestral
# calculamos las medias de cada estimador
mean(var.1) # la media de la cuasivarianza se aproxima bien al teorico
mean(var.2) # la media de la varianza muestral no se aproxima bien
(50/49)*mean(var.2) # si se multiplica por (n/(n-1)) se aproxima mejor
# Distribucion muestral de la cuasivarianza
chi2 <- 49*var.1/(1/12) # estadistico chi cuadrado
hist(chi2, freq = FALSE)
curve(dchisq(x, 49), 20, 80, col = 2, add = TRUE)
###################################
# DISTRIBUCIONES RELACIONADAS A LA NORMAL
# OJO: uso de prefijos de funciones: d., p., q., r.
###################################
# ESTUDIO DE LOS ESTIMADORES PARA UNA MEDIA
set.seed(1234) #fijamos semillas
# generamos 1000 muestras uniformes (0,1) de tamaño n = 50
datos <- replicate(1000, runif(50))
#histograma de las muestras
hist(datos)
mean(datos)# OJO: la media teórica es el valor de 0.5
sd(datos)
sqrt(1/12) # OJO: varianza teórica (a-b)^2/12
# Consideraremos dos estimadores para la media poblacional teorica
# estimador 1: el promedio
# estimador 2: la mediana
# calculamos ambos estimadores en las 1000 muestras
est1 <- apply(datos, 2, mean)
est2 <- apply(datos, 2, median)
#OJO: se observa que  los estimadores son v.a.
# comparamos los histogramas de los estimadores
windows()
par(mfrow = c(1,2))
hist(est1)
hist(est2)
par(mfrow = c(1,1))
# OJO: ninguno de los estimadores sigue una distribución uniforme (0,1)
# comparamos los estadisticos
mean(est1)
mean(est2)
# los dos estimadores aproximan al parametro = 0.5
# calculamos el sesgo de cada estimador
sesgo1 <- mean(est1) - 0.5
sesgo1
sesgo2 <- mean(est2) - 0.5
sesgo2
# ambos estimadores tiene sesgo casi nulos (est 1 < est 2)
#calculamos la varianza de cada estimador
var1 <- var(est1)
var1
var2 <- var(est2)
var2
# estimador 1 tiene menos variabilidad que el estimador 2
#calculamos el error cuadratico medio
ecm1 <- sesgo1^2 + var1
ecm1
ecm2 <- sesgo2^2 + var2
ecm2
# el estimador 1 (promedio) es mas eficiente que el estimador 2 (mediana)
###################################
# TEOREMA CENTRAL DEL LIMITE
# se tomaron muestras de tamaño n = 50, y se obtuvo el promedio
# en cada muestra. Para este estimador sucede lo siguiente:
mean(est1) # su media "coincide" con la media teorica = 0.5
sd(est1) # desviacion tipica del estimador
sqrt(1/12)/sqrt(50) # error tipico = desv. del estimador
# Visualizacion del teorema central del limite
hist(est1, freq = FALSE, ylim =c(0,10))
curve(dnorm(x, 0.5, sqrt(1/12)/sqrt(50) ), 0.3, 0.7, add = TRUE, col = 2)
###################################
# ESTIMACION DE LA VARIANZA POBLACIONAL
#Ojo: la varianza poblacional teorica es = 1/12
1/12
# calculamos dos estimadores: varianza muestral y cuasivarianza
var.1 <- apply(datos, 2, var) #cuasivarianza
varp.f <- function(x) mean((x-mean(x))^2) #funcion varianza muestral
var.2 <- apply(datos, 2, varp.f) #varianza muestral
# calculamos las medias de cada estimador
mean(var.1) # la media de la cuasivarianza se aproxima bien al teorico
mean(var.2) # la media de la varianza muestral no se aproxima bien
(50/49)*mean(var.2) # si se multiplica por (n/(n-1)) se aproxima mejor
# Distribucion muestral de la cuasivarianza
chi2 <- 49*var.1/(1/12) # estadistico chi cuadrado
hist(chi2, freq = FALSE)
curve(dchisq(x, 49), 20, 80, col = 2, add = TRUE)
gl = ((((5.6^2)-50)+(6.3^2)/50))^2 / (((5.6^2)/50)/49 + ((6.3^2)/50)/49)
gl
gl = ((((5.6^2)/50)+(6.3^2)/50))^2 / (((5.6^2)/50)/49 + ((6.3^2)/50)/49)
gl
gl = ceiling(gl)
gl
tmin = qt(0.025, gl)
tmax = qt(0.095, gl)
tmin; tmax
tmin = qt(0.025, gl)
tmax = qt(0.975, gl)
tmin; tmax
error = tmax * sqrt((5.6^2)/50 + (6.3^2)/50)
error
LIC = (78.3 - 87.2) - err
LIC = (78.3 - 87.2) - error
LSC = (78.3 - 87.2) + error
LIC, LSC
LIC; LSC
n1=12
prom1 = 37900
s1 = 5100
n2 = 12
prom2 = 39800
s2 = 5900
var.c = ((n1-1)*s1^2 + (n2-1)*s2^2) / (n1 +n2 - 2)
var.c
desv.c = sqrt(var.c)
desv.c
t_prom
t_prom = (prom1 - prom2) / (desv.c * sqrt(1/n1 + 1/n2))
t_prom
pt(t_prom, n1+n2-2)
pvalor= 2 * pt(t_prom, n1+n2-2)
pvalor
n = 200 #votantes
exito = 110
prop_muestral = 100/200
prop_muestral
n = 200 #votantes
exito = 110
prop_muestral = n/200
prop_muestral
n = 200 #votantes
exito = 110
prop_muestral = exito/n
prop_muestral
ztest = (p-p0)/sqrt(p0*(1-p0)/n)
n = 200 #votantes
exito = 110
prop_muestral = exito/n
p0=0.6
ztest = (p-p0)/sqrt(p0*(1-p0)/n)
ztest = (prop_muestral-p0)/sqrt(p0*(1-p0)/n)
ztest
Pvalor = pnorm(ztest)
Pvalor
n1 = 100
x1 = 63 #existos
p_1 = x1/n1
p_1
n2 = 125
x2 = 59 #exitos
p_2 = x2/n2
p_2
n3= 20
exito2 = 9
p_muestral = exito2/n3
p_0=0.4
ztest2 = (p_muestral-p_0)/sqrt(p_0*(1-p_0)/0.4)
ztest2
pvalor = pnorm(ztest2)
pvalor
2*pvalor
n3= 20
exito2 = 9
p_muestral = exito2/n3
p_0=0.4
ztest2 = (p_muestral-p_0)/sqrt(p_0*(1-p_0)/p_0)
ztest2
library(DT)
install.packages(DT)
install.packages("DT")
install.packages("dplyr")
install.packages("tidyr")
install.packages("ggplot2")
install.packages("markdown")
library(shiny)
library(DT)
library(DT)
library(dplyr)
library(tidyr)
library(ggplot2)
library(ggplot2)
library(markdown)
install.packages(c("cachem", "cli", "colorspace", "crayon", "digest", "evaluate", "fastmap", "highr", "knitr", "openssl", "PKI", "Rcpp", "rlang", "rmarkdown", "rsconnect", "tinytex", "xfun", "yaml"))
shiny::runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
shiny::runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
shiny::runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
shiny::runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
shiny::runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
################
# REGRESION LINEAL MULTIPLE
#################
# CARGAR LOS DATOS
y = c(240,165,190,274,301) #
x1 = c(25,31,45,60,65) #
x2 = c(91,90,88,87,91) #
n = 5 # total de observaciones
p = 3 # total de coeficientes betas a estimar
# Construir las matrices
Y = matrix(y, nrow = 5) # vector Y
Y
X = matrix(c(rep(1,n),x1,x2), ncol = p) # matriz de diseño
X
# Construir el sistema de ecuaciones normales A*beta = b
t(X) # transpuesta de X
A = t(X) %*% X # Ojo: multiplicacion matricial = %*%
A
b = t(X) %*% Y
b
Ainv = solve(A) # matriz inversa de A
Ainv
Beta = Ainv %*% b # estimacion por MCO del vector Beta
Beta
# Proyecciones de Y
Yproy = X %*% Beta
Yproy
# Residuos
resid = Y - Yproy
resid
# sumatorias de residuos
sum(resid) # muy cercano a cero!
SCR = sum(resid^2)
SCR
t(resid)%*%resid # SCR de forma matricial
# Estimacion de la varianza del error (varianza de los residuos)
sigma2 = SCR / (n-p)
sigma2
sigma = sqrt(sigma2)
sigma
# Matriz de proyeccion H
H = X %*% Ainv %*% t(X) # matriz de proyeccion H
H
H %*% Y # vector de proyecciones de Y
# Matriz generadora de residuos
diag(n)
M = (diag(n) - H) # matriz identidad de tamaño n = diag(n)
M
M %*% Y # vector de residuos
t(H) %*% M
################
# REGRESION LINEAL MULTIPLE
#################
# CARGAR LOS DATOS
y = c(240,165,190,274,301) #
x1 = c(25,31,45,60,65) #
x2 = c(91,90,88,87,91) #
n = 5 # total de observaciones
p = 3 # total de coeficientes betas a estimar
# Construir las matrices
Y = matrix(y, nrow = 5) # vector Y
Y
X = matrix(c(rep(1,n),x1,x2), ncol = p) # matriz de diseño
X
# Construir el sistema de ecuaciones normales A*beta = b
t(X) # transpuesta de X
A = t(X) %*% X # Ojo: multiplicacion matricial = %*%
A
b = t(X) %*% Y
b
# Estimar el vector Beta
Ainv = solve(A) # matriz inversa de A
Ainv
Beta = Ainv %*% b # estimacion por MCO del vector Beta
Beta
# Proyecciones de Y
Yproy = X %*% Beta
Yproy
# Residuos
resid = Y - Yproy
resid
# sumatorias de residuos
sum(resid) # muy cercano a cero!
SCR = sum(resid^2)
SCR
t(resid)%*%resid # SCR de forma matricial
# Estimacion de la varianza del error (varianza de los residuos)
sigma2 = SCR / (n-p)
sigma2
sigma = sqrt(sigma2)
sigma
# Matriz de proyeccion H
H = X %*% Ainv %*% t(X) # matriz de proyeccion H
H
H %*% Y # vector de proyecciones de Y
# Matriz generadora de residuos
diag(n)
M = (diag(n) - H) # matriz identidad de tamaño n = diag(n)
M
M %*% Y # vector de residuos
t(H) %*% M
= %*%
shiny::runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
shiny::runApp('C:/Users/EDWARICHSNAKE/Desktop/Estadistica/Unidad_2_Proyecto')
